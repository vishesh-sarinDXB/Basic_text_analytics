{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "\n",
    "\n",
    "# Installation\n",
    "You need first to open your envirnoment and install the NLTK package \n",
    "\n",
    "`!pip install nltk`\n",
    "\n",
    "`!pip install spacy`\n",
    "\n",
    "`python -m spacy download en`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kayvan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying bag-of-words to a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =  CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary content:\n",
      " {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vect.transform(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense representation of bag_of_words:\n",
      "[[0 0 1 1 1 0 1 0 0 1 2 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense representation of bag_of_words:\\n{}\".format(\n",
    "    bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'but', 'doth', 'fool', 'he', 'himself', 'is', 'knows', 'man', 'the', 'think', 'to', 'wise']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34262</td>\n",
       "      <td>0.243777</td>\n",
       "      <td>0.34262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243777</td>\n",
       "      <td>0.68524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         be       but     doth      fool       he   himself       is  \\\n",
       "0  0.000000  0.000000  0.34262  0.243777  0.34262  0.000000  0.34262   \n",
       "1  0.364693  0.364693  0.00000  0.259482  0.00000  0.364693  0.00000   \n",
       "\n",
       "      knows       man       the    think        to      wise  \n",
       "0  0.000000  0.000000  0.243777  0.68524  0.000000  0.243777  \n",
       "1  0.364693  0.364693  0.259482  0.00000  0.364693  0.259482  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vec = vectors.todense()\n",
    "dense_list = dense_vec.tolist()\n",
    "tfidf_data = pd.DataFrame(dense_list, columns=feature_names)\n",
    "tfidf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy version: 2.2.3\n",
      "nltk version: 3.4.5\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(\"SpaCy version: {}\".format(spacy.__version__))\n",
    "print(\"nltk version: {}\".format(nltk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy's English-language models\n",
    "en_nlp = spacy.load('en')\n",
    "# instantiate nltk's Porter stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "# define function to compare lemmatization in spacy with stemming in nltk\n",
    "def compare_normalization(doc):\n",
    "    # tokenize document in spacy\n",
    "    doc_spacy = en_nlp(doc)\n",
    "    # print lemmas found by spacy\n",
    "    print(\"Lemmatization:\")\n",
    "    print([token.lemma_ for token in doc_spacy])\n",
    "    # print tokens found by Porter stemmer\n",
    "    print(\"Stemming:\")\n",
    "    print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:\n",
      "['-PRON-', 'meeting', 'today', 'be', 'bad', 'than', 'yesterday', ',', '-PRON-', 'be', 'scared', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n",
      "Stemming:\n",
      "['our', 'meet', 'today', 'wa', 'wors', 'than', 'yesterday', ',', 'i', 'am', 'scare', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "compare_normalization(u\"Our meeting today was worse than yesterday, \"\n",
    "                       \"I'm scared of meeting the clients tomorrow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
