{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDtype = pd.CategoricalDtype(['1','2','3','4','5'], ordered= True)\n",
    "train = pd.read_csv(\"train2electricboogaloo.csv\", dtype={'Score':catDtype})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39193\n",
       "5        0\n",
       "4        0\n",
       "3        0\n",
       "2        0\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Score.value_counts()\n",
    "df_class_5 = train[train['Score'] == \"1\"]\n",
    "df_class_5.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df_class_5[\"Summary\"] + \" \" + df_class_5[\"Text\"]\n",
    "scores = df_class_5[\"Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace na from the review column\n",
    "reviews.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace html tags\n",
    "from bs4 import BeautifulSoup\n",
    "reviews = [BeautifulSoup(text).get_text() for text in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove digits, punctiuation, and special character. Make it all lower case\n",
    "remove_digits = str.maketrans('', '', digits) \n",
    "remove_special_char = str.maketrans('', '', '@#%$/*')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stop_words(reviews):\n",
    "    nostop=[]\n",
    "    for review in reviews:\n",
    "        words = review.split()\n",
    "        sent = ''\n",
    "        for word in words:\n",
    "            if word.lower() not in stop_words:\n",
    "                sent = sent + word + (' ')\n",
    "       # print(sent)\n",
    "        nostop.append(sent)\n",
    "    return nostop\n",
    "\n",
    "\n",
    "def basic_data_cleaning(unprocessed):\n",
    "    nopunc = [word.translate(str.maketrans('', '', string.punctuation)) for word in unprocessed]\n",
    "    to_lowered = [word.lower() for word in nopunc]\n",
    "    nodigits = [word.translate(remove_digits).translate(remove_special_char) for word in to_lowered]\n",
    "    nostop = remove_stop_words(nodigits)\n",
    "    return nostop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the sample size \n",
    "reviews_subset = reviews[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews = basic_data_cleaning(reviews_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import mglearn as mglearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config 1 - basic cleaning (Remove digits, punctiuation, and special character. Make it all lower case)\n",
    "#Remove words that are in 15% of the documents - 10 topic\n",
    "vect = CountVectorizer(max_df=.15)\n",
    "X = vect.fit_transform(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0, n_jobs=-1)\n",
    "# We build the model and transform the data in one step\n",
    "# Computing transform takes some time,\n",
    "# and we can save time by doing both at once\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 44132)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each topic (a row in the components_), sort the features (ascending).\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# get the feature names from the vectorizer:\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "sauce         food          formula       coffee        dog           \n",
      "gluten        cat           new           cup           dogs          \n",
      "free          dog           baby          flavor        made          \n",
      "rice          eating        time          tried         treats        \n",
      "mix           eat           use           tastes        china         \n",
      "bread         cats          used          water         chicken       \n",
      "time          day           changed       drink         products      \n",
      "noodles       got           old           bad           food          \n",
      "make          back          hair          kcups         sick          \n",
      "cake          little        work          bitter        pet           \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "tea           flavor        water         price         amazon        \n",
      "food          chocolate     sugar         store         order         \n",
      "cat           bad           ingredients   oz            ordered       \n",
      "chicken       really        coconut       much          box           \n",
      "ingredients   tastes        bottle        amazon        received      \n",
      "green         eat           syrup         pack          item          \n",
      "cats          tried         natural       size          bag           \n",
      "eat           tasted        organic       expensive     opened        \n",
      "corn          try           contains      shipping      disappointed  \n",
      "meat          sweet         artificial    cost          time          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the 10 topics:\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer()\n",
    "X2 = vect2.fit_transform(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda2 = LatentDirichletAllocation(n_components=5, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0, n_jobs=-1)\n",
    "\n",
    "document_topics_2 = lda2.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each topic (a row in the components_), sort the features (ascending).\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting2 = np.argsort(lda2.components_, axis=1)[:, ::-1]\n",
    "# get the feature names from the vectorizer:\n",
    "feature_names2 = np.array(vect2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "food          coffee        product       like          ingredients   \n",
      "dog           tea           amazon        taste         product       \n",
      "dogs          cup           box           flavor        food          \n",
      "one           food          order         good          products      \n",
      "would         would         price         one           corn          \n",
      "product       kcups         ordered       tastes        sugar         \n",
      "made          eating        one           even          organic       \n",
      "treats        green         received      dont          made          \n",
      "eat           day           buy           would         ingredient    \n",
      "cat           really        would         bad           natural       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the 5 topics:\n",
    "mglearn.tools.print_topics(topics=range(5), feature_names=feature_names2,\n",
    "                           sorting=sorting2, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect3 = CountVectorizer(max_df=.25)\n",
    "X3 = vect3.fit_transform(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda3 = LatentDirichletAllocation(n_components=5, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0, n_jobs=-1)\n",
    "\n",
    "document_topics3 = lda3.fit_transform(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each topic (a row in the components_), sort the features (ascending).\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting3 = np.argsort(lda3.components_, axis=1)[:, ::-1]\n",
    "# get the feature names from the vectorizer:\n",
    "feature_names3 = np.array(vect3.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "food          dog           amazon        flavor        coffee        \n",
      "cat           dogs          box           good          tea           \n",
      "ingredients   made          order         sugar         flavor        \n",
      "cats          food          one           would         one           \n",
      "eat           one           price         dont          good          \n",
      "would         treats        ordered       one           water         \n",
      "eating        would         buy           chips         even          \n",
      "diet          china         received      chocolate     tried         \n",
      "chicken       time          would         eat           tastes        \n",
      "corn          bag           item          really        would         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the 10 topics:\n",
    "mglearn.tools.print_topics(topics=range(5), feature_names=feature_names3,\n",
    "                           sorting=sorting3, topics_per_chunk=5, n_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
