{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "import sklearn\n",
    "import re\n",
    "# import mglearn as mglearn\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2electricboogaloo.csv')\n",
    "\n",
    "train.Summary.fillna('', inplace=True)\n",
    "train.Text.fillna('', inplace=True)\n",
    "train.SumTxt.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(train, test_size = 0.2, random_state = 42, stratify = train['Score'])\n",
    "train_text, train_score = train_set['SumTxt'], train_set['Score']\n",
    "test_text, test_score = test_set['SumTxt'], test_set['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, score = train['SumTxt'], train['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "lem = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "    \"ain\\'t\": \"am not\",\n",
    "    \"aren\\'t\": \"are not\",\n",
    "    \"can\\'t\": \"cannot\",\n",
    "    \"can\\'t\\'ve\": \"cannot have\",\n",
    "    \"\\'cause\": \"because\",\n",
    "    \"could\\'ve\": \"could have\",\n",
    "    \"couldn\\'t\": \"could not\",\n",
    "    \"couldn\\'t\\'ve\": \"could not have\",\n",
    "    \"didn\\'t\": \"did not\",\n",
    "    \"doesn\\'t\": \"does not\",\n",
    "    \"don\\'t\": \"do not\",\n",
    "    \"hadn\\'t\": \"had not\",\n",
    "    \"hadn\\'t\\'ve\": \"had not have\",\n",
    "    \"hasn\\'t\": \"has not\",\n",
    "    \"haven\\'t\": \"have not\",\n",
    "    \"he\\'d\": \"he had\",\n",
    "    \"he\\'d\\'ve\": \"he would have\",\n",
    "    \"he\\'ll\": \"he shall\",\n",
    "    \"he\\'ll\\'ve\": \"he shall have\",\n",
    "    \"he\\'s\": \"he has\",\n",
    "    \"how\\'d\": \"how did\",\n",
    "    \"how\\'d\\'y\": \"how do you\",\n",
    "    \"how\\'ll\": \"how will\",\n",
    "    \"how\\'s\": \"how has\",\n",
    "    \"I\\'d\": \"I had\",\n",
    "    \"I\\'d\\'ve\": \"I would have\",\n",
    "    \"I\\'ll\": \"I will\",\n",
    "    \"I\\'ll\\'ve\": \"I will have\",\n",
    "    \"I\\'m\": \"I am\",\n",
    "    \"I\\'ve\": \"I have\",\n",
    "    \"isn\\'t\": \"is not\",\n",
    "    \"it\\'d\": \"it would\",\n",
    "    \"it\\'d\\'ve\": \"it would have\",\n",
    "    \"it\\'ll\": \"it will\",\n",
    "    \"it\\'ll\\'ve\": \"it will have\",\n",
    "    \"it\\'s\": \"it is\",\n",
    "    \"let\\'s\": \"let us\",\n",
    "    \"ma\\'am\": \"madam\",\n",
    "    \"mayn\\'t\": \"may not\",\n",
    "    \"might\\'ve\": \"might have\",\n",
    "    \"mightn\\'t\": \"might not\",\n",
    "    \"mightn\\'t\\'ve\": \"might not have\",\n",
    "    \"must\\'ve\": \"must have\",\n",
    "    \"mustn\\'t\": \"must not\",\n",
    "    \"mustn\\'t\\'ve\": \"must not have\",\n",
    "    \"needn\\'t\": \"need not\",\n",
    "    \"needn\\'t\\'ve\": \"need not have\",\n",
    "    \"o\\'clock\": \"of the clock\",\n",
    "    \"oughtn\\'t\": \"ought not\",\n",
    "    \"oughtn\\'t\\'ve\": \"ought not have\",\n",
    "    \"shan\\'t\": \"shall not\",\n",
    "    \"sha\\'n\\'t\": \"shall not\",\n",
    "    \"shan\\'t\\'ve\": \"shall not have\",\n",
    "    \"she\\'d\": \"she had\",\n",
    "    \"she\\'d\\'ve\": \"she would have\",\n",
    "    \"she\\'ll\": \"she will\",\n",
    "    \"she\\'ll\\'ve\": \"she will have\",\n",
    "    \"she\\'s\": \"she is\",\n",
    "    \"should\\'ve\": \"should have\",\n",
    "    \"shouldn\\'t\": \"should not\",\n",
    "    \"shouldn\\'t\\'ve\": \"should not have\",\n",
    "    \"so\\'ve\": \"so have\",\n",
    "    \"so\\'s\": \"so as\",\n",
    "    \"that\\'d\": \"that would\",\n",
    "    \"that\\'d\\'ve\": \"that would have\",\n",
    "    \"that\\'s\": \"that is\",\n",
    "    \"there\\'d\": \"there had\",\n",
    "    \"there\\'d\\'ve\": \"there would have\",\n",
    "    \"there\\'s\": \"there has\",\n",
    "    \"they\\'d\": \"they had\",\n",
    "    \"they\\'d\\'ve\": \"they would have\",\n",
    "    \"they\\'ll\": \"they will\",\n",
    "    \"they\\'ll\\'ve\": \"they will have\",\n",
    "    \"they\\'re\": \"they are\",\n",
    "    \"they\\'ve\": \"they have\",\n",
    "    \"to\\'ve\": \"to have\",\n",
    "    \"wasn\\'t\": \"was not\",\n",
    "    \"we\\'d\": \"we had\",\n",
    "    \"we\\'d\\'ve\": \"we would have\",\n",
    "    \"we\\'ll\": \"we will\",\n",
    "    \"we\\'ll\\'ve\": \"we will have\",\n",
    "    \"we\\'re\": \"we are\",\n",
    "    \"we\\'ve\": \"we have\",\n",
    "    \"weren\\'t\": \"were not\",\n",
    "    \"what\\'ll\": \"what will\",\n",
    "    \"what\\'ll\\'ve\": \"what will have\",\n",
    "    \"what\\'re\": \"what are\",\n",
    "    \"what\\'s\": \"what is\",\n",
    "    \"what\\'ve\": \"what have\",\n",
    "    \"when\\'s\": \"when is\",\n",
    "    \"when\\'ve\": \"when have\",\n",
    "    \"where\\'d\": \"where did\",\n",
    "    \"where\\'s\": \"where has\",\n",
    "    \"where\\'ve\": \"where have\",\n",
    "    \"who\\'ll\": \"who will\",\n",
    "    \"who\\'ll\\'ve\": \"who will have\",\n",
    "    \"who\\'s\": \"who is\",\n",
    "    \"who\\'ve\": \"who have\",\n",
    "    \"why\\'s\": \"why is\",\n",
    "    \"why\\'ve\": \"why have\",\n",
    "    \"will\\'ve\": \"will have\",\n",
    "    \"won\\'t\": \"will not\",\n",
    "    \"won\\'t\\'ve\": \"will not have\",\n",
    "    \"would\\'ve\": \"would have\",\n",
    "    \"wouldn\\'t\": \"would not\",\n",
    "    \"wouldn\\'t\\'ve\": \"would not have\",\n",
    "    \"y\\'all\": \"you all\",\n",
    "    \"y\\'all\\'d\": \"you all would\",\n",
    "    \"y\\'all\\'d\\'ve\": \"you all would have\",\n",
    "    \"y\\'all\\'re\": \"you all are\",\n",
    "    \"y\\'all\\'ve\": \"you all have\",\n",
    "    \"you\\'d\": \"you would\",\n",
    "    \"you\\'d\\'ve\": \"you would have\",\n",
    "    \"you\\'ll\": \"you will\",\n",
    "    \"you\\'ll\\'ve\": \"you will have\",\n",
    "    \"you\\'re\": \"you are\",\n",
    "    \"you\\'ve\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    x = [contractions_dict[con] if con in contractions_dict else con for con in s.split()]\n",
    "    x = ' '.join(x)\n",
    "    return decontracted(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(mess):\n",
    "    return ''.join([i for i in mess if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stm(mess):\n",
    "    return [stemmer.stem(word) for word in mess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnl(mess):\n",
    "    return [lem.lemmatize(word) for word in mess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swr(mess):\n",
    "    return ' '.join([word for word in mess.split() if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc(mess):\n",
    "    return mess.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_char(mess):\n",
    "    return [word for word in mess.split() if len(word) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def css(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = expand_contractions(mess)\n",
    "    mess = swr(mess)\n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return stm(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csl(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = expand_contractions(mess)\n",
    "    mess = swr(mess)\n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return wnl(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nss(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = swr(mess)\n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return stm(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsl(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = swr(mess)\n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return wnl(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cns(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = expand_contractions(mess)\n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return stm(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnl(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = expand_contractions(mess)\n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return wnl(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nns(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return stm(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnl(mess):\n",
    "    mess = remove_digits(mess) \n",
    "    mess = punc(mess)\n",
    "    mess = check_char(mess)\n",
    "    return wnl(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer = nsl)),\n",
    "    ('log', LogisticRegression())\n",
    "])\n",
    "\n",
    "m = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer = nsl)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "s = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer = nsl)),\n",
    "    ('svm', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_l = {#'tfidf__analyzer': [css, csl, nss, nsl, nns, nnl, cns, cnl],\n",
    "              'tfidf__min_df': [0.1, 0.2],\n",
    "#               'tfidf__max_features': [50000, None],\n",
    "              'tfidf__binary': [True, False],\n",
    "#               'tfidf__norm': ['l1', 'l2', None],\n",
    "              'tfidf__use_idf': [True, False],\n",
    "              'log__C': [1, 10, 100],\n",
    "#               'log__fit_intercept': [True, False]\n",
    "             }\n",
    "\n",
    "param_grid_m = {#'tfidf__analyzer': [css, csl],\n",
    "#               'tfidf__max_df': [0.8, 0.9, 1],\n",
    "              'tfidf__min_df': [0.1, 0.2],\n",
    "#               'tfidf__max_features': [50000, None],\n",
    "              'tfidf__binary': [True, False],\n",
    "#               'tfidf__norm': ['l1', 'l2', None],\n",
    "              'tfidf__use_idf': [True, False],\n",
    "              'mnb__alpha': [0.01, 0.5, 1]\n",
    "             }\n",
    "\n",
    "param_grid_s = {#'tfidf__analyzer': [css, csl],\n",
    "#               'tfidf__max_df': [0.8, 0.9, 1],\n",
    "              'tfidf__min_df': [0.1, 0.2],\n",
    "#               'tfidf__max_features': [50000, None],\n",
    "              'tfidf__binary': [True, False],\n",
    "#               'tfidf__norm': ['l1', 'l2', None],\n",
    "              'tfidf__use_idf': [True, False],\n",
    "              'svm__C': [1, 10, 100],\n",
    "#               'svm__loss': ['hinge']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_l = GridSearchCV(l, param_grid_l, n_jobs = 7)\n",
    "grid_m = GridSearchCV(m, param_grid_m, n_jobs = 7)\n",
    "grid_s = GridSearchCV(s, param_grid_s, n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer=<function nsl at 0x7faa760efb90>,\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True...\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'svm__C': [1, 10, 100], 'tfidf__binary': [True, False],\n",
       "                         'tfidf__min_df': [0.1, 0.2],\n",
       "                         'tfidf__use_idf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s.fit(train_text, train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "print(grid_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.001) for {'svm__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.001) for {'svm__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'svm__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "means = grid_s.cv_results_['mean_test_score']\n",
    "stds = grid_s.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_s.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s = grid_s.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.01      0.03      7838\n",
      "           2       0.00      0.00      0.00      4471\n",
      "           3       0.00      0.00      0.00      6399\n",
      "           4       0.27      0.00      0.00     12062\n",
      "           5       0.64      1.00      0.78     54498\n",
      "\n",
      "    accuracy                           0.64     85268\n",
      "   macro avg       0.26      0.20      0.16     85268\n",
      "weighted avg       0.48      0.64      0.50     85268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score, pred_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer=<function nsl at 0x7faa760efb90>,\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'log__C': [1, 10, 100], 'tfidf__binary': [True, False],\n",
       "                         'tfidf__min_df': [0.1, 0.2],\n",
       "                         'tfidf__use_idf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_l.fit(train_text, train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "print(grid_l.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640 (+/-0.001) for {'log__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.640 (+/-0.001) for {'log__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'log__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'log__C': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.640 (+/-0.001) for {'log__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.640 (+/-0.001) for {'log__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'log__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'log__C': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.640 (+/-0.001) for {'log__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.640 (+/-0.001) for {'log__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'log__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'log__C': 10, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.640 (+/-0.001) for {'log__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.640 (+/-0.001) for {'log__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'log__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'log__C': 10, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.640 (+/-0.001) for {'log__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.640 (+/-0.001) for {'log__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'log__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'log__C': 100, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.640 (+/-0.001) for {'log__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.640 (+/-0.001) for {'log__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'log__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'log__C': 100, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "means = grid_l.cv_results_['mean_test_score']\n",
    "stds = grid_l.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_l.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_l = grid_l.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.07      0.11      7838\n",
      "           2       0.00      0.00      0.00      4471\n",
      "           3       0.20      0.00      0.00      6399\n",
      "           4       0.30      0.00      0.01     12062\n",
      "           5       0.64      0.99      0.78     54498\n",
      "\n",
      "    accuracy                           0.64     85268\n",
      "   macro avg       0.31      0.21      0.18     85268\n",
      "weighted avg       0.51      0.64      0.51     85268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score, pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer=<function nsl at 0x7faa760efb90>,\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True...\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('mnb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'mnb__alpha': [0.01, 0.5, 1],\n",
       "                         'tfidf__binary': [True, False],\n",
       "                         'tfidf__min_df': [0.1, 0.2],\n",
       "                         'tfidf__use_idf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_m.fit(train_text, train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnb__alpha': 0.01, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "print(grid_m.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.01, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 0.5, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': True, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.1, 'tfidf__use_idf': False}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': True}\n",
      "0.639 (+/-0.000) for {'mnb__alpha': 1, 'tfidf__binary': False, 'tfidf__min_df': 0.2, 'tfidf__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "means = grid_m.cv_results_['mean_test_score']\n",
    "stds = grid_m.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_m.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m = grid_m.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00      7838\n",
      "           2       0.00      0.00      0.00      4471\n",
      "           3       0.00      0.00      0.00      6399\n",
      "           4       0.00      0.00      0.00     12062\n",
      "           5       0.64      1.00      0.78     54498\n",
      "\n",
      "    accuracy                           0.64     85268\n",
      "   macro avg       0.13      0.20      0.16     85268\n",
      "weighted avg       0.41      0.64      0.50     85268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score, pred_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidfnew = TfidfVectorizer(strip_accents='unicode', analyzer='word', min_df=0.1, max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='unicode', analyzer='word', min_df=0.1, max_df=0.8)),\n",
    "    ('svm', LinearSVC(loss = 'hinge', C = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_s2 = {#'tfidf__analyzer': [css, csl],\n",
    "#               'tfidf__max_df': [0.8, 0.9, 1],\n",
    "#               'tfidf__min_df': [0.1, 0.2],\n",
    "#               'tfidf__max_features': [50000, None],\n",
    "#               'tfidf__binary': [True, False],\n",
    "#               'tfidf__norm': ['l1', 'l2', None],\n",
    "#               'tfidf__use_idf': [True, False],\n",
    "#               'svm__C': [1, 10, 100],\n",
    "#               'svm__loss': ['hinge']\n",
    "                'tfidf__ngram_range': [(1,1), (1,2), (2,2)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s2 = GridSearchCV(s2, param_grid_s2, n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...\n",
       "                                        LinearSVC(C=10, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='hinge', max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=6,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s2.fit(train_text, train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643 (+/-0.004) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.642 (+/-0.003) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.639 (+/-0.000) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_s2.cv_results_['mean_test_score']\n",
    "stds = grid_s2.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_s2.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s2 = grid_s2.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.02      0.04      7838\n",
      "           2       0.26      0.00      0.01      4471\n",
      "           3       0.24      0.11      0.15      6399\n",
      "           4       0.19      0.05      0.08     12062\n",
      "           5       0.68      0.98      0.80     54498\n",
      "\n",
      "    accuracy                           0.64     85268\n",
      "   macro avg       0.37      0.23      0.22     85268\n",
      "weighted avg       0.53      0.64      0.54     85268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score, pred_s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_s2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235149    5\n",
       "419454    4\n",
       "233664    5\n",
       "295342    5\n",
       "332103    5\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9823      4\n",
       "247438    5\n",
       "107574    4\n",
       "37202     1\n",
       "334756    5\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>NumProdReviews</th>\n",
       "      <th>UserId</th>\n",
       "      <th>NumUserReviews</th>\n",
       "      <th>HelpfulRatio</th>\n",
       "      <th>FoundHelpful</th>\n",
       "      <th>HelpfulVotes</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SumTxt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0034EDLS2</td>\n",
       "      <td>249</td>\n",
       "      <td>AVF82BC7S0IO7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1332806400</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I received this product early from the seller!...</td>\n",
       "      <td>Very Good I received this product early from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001I7HJE4</td>\n",
       "      <td>1</td>\n",
       "      <td>A1YUL9PCJR3JTY</td>\n",
       "      <td>312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1190160000</td>\n",
       "      <td>Organic, Kosher, Tasty Assortment of Premium T...</td>\n",
       "      <td>***** Numi's Collection Assortment Melange inc...</td>\n",
       "      <td>Organic, Kosher, Tasty Assortment of Premium T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LKTB90</td>\n",
       "      <td>44</td>\n",
       "      <td>A1BBPP1EC75JX4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1285977600</td>\n",
       "      <td>excellent gluten-free spaghetti: great taste, ...</td>\n",
       "      <td>I was very careful not to overcook this pasta,...</td>\n",
       "      <td>excellent gluten-free spaghetti: great taste, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B001HXJPS2</td>\n",
       "      <td>3</td>\n",
       "      <td>A5QSI9MNS8NMS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338163200</td>\n",
       "      <td>Lindt is Lindt</td>\n",
       "      <td>Buying this multi-pack I was misled by the pic...</td>\n",
       "      <td>Lindt is Lindt Buying this multi-pack I was mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006H34CUS</td>\n",
       "      <td>251</td>\n",
       "      <td>A20IBAIRSNBEAQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1343606400</td>\n",
       "      <td>YUM!!!!!</td>\n",
       "      <td>These bars are so good! I loved them warmed up...</td>\n",
       "      <td>YUM!!!!! These bars are so good! I loved them ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProdID  NumProdReviews          UserId  NumUserReviews  HelpfulRatio  \\\n",
       "0  B0034EDLS2             249   AVF82BC7S0IO7               5           0.0   \n",
       "1  B001I7HJE4               1  A1YUL9PCJR3JTY             312           1.0   \n",
       "2  B000LKTB90              44  A1BBPP1EC75JX4               1           0.0   \n",
       "3  B001HXJPS2               3   A5QSI9MNS8NMS               4           0.0   \n",
       "4  B006H34CUS             251  A20IBAIRSNBEAQ               1           0.0   \n",
       "\n",
       "   FoundHelpful  HelpfulVotes  Score        Time  \\\n",
       "0             0             0      5  1332806400   \n",
       "1             1             1      5  1190160000   \n",
       "2             0             0      5  1285977600   \n",
       "3             0             0      5  1338163200   \n",
       "4             0             0      5  1343606400   \n",
       "\n",
       "                                             Summary  \\\n",
       "0                                          Very Good   \n",
       "1  Organic, Kosher, Tasty Assortment of Premium T...   \n",
       "2  excellent gluten-free spaghetti: great taste, ...   \n",
       "3                                     Lindt is Lindt   \n",
       "4                                           YUM!!!!!   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I received this product early from the seller!...   \n",
       "1  ***** Numi's Collection Assortment Melange inc...   \n",
       "2  I was very careful not to overcook this pasta,...   \n",
       "3  Buying this multi-pack I was misled by the pic...   \n",
       "4  These bars are so good! I loved them warmed up...   \n",
       "\n",
       "                                              SumTxt  \n",
       "0  Very Good I received this product early from t...  \n",
       "1  Organic, Kosher, Tasty Assortment of Premium T...  \n",
       "2  excellent gluten-free spaghetti: great taste, ...  \n",
       "3  Lindt is Lindt Buying this multi-pack I was mi...  \n",
       "4  YUM!!!!! These bars are so good! I loved them ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_score(score):\n",
    "    if score == 4 or score == 3 or score == 2 or score == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['score2'] = train.apply(lambda x: new_score(x['Score']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>NumProdReviews</th>\n",
       "      <th>UserId</th>\n",
       "      <th>NumUserReviews</th>\n",
       "      <th>HelpfulRatio</th>\n",
       "      <th>FoundHelpful</th>\n",
       "      <th>HelpfulVotes</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SumTxt</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426335</th>\n",
       "      <td>B00028LDJ2</td>\n",
       "      <td>5</td>\n",
       "      <td>A28AJSK2CI1XAO</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1203379200</td>\n",
       "      <td>i like it</td>\n",
       "      <td>Like a lot of the gums by Lotte, the flavor do...</td>\n",
       "      <td>i like it Like a lot of the gums by Lotte, the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426336</th>\n",
       "      <td>B000BZZKVS</td>\n",
       "      <td>59</td>\n",
       "      <td>ACHJKSYDTDKMU</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1247702400</td>\n",
       "      <td>The Anti-Fatigue</td>\n",
       "      <td>This is a fantastic product.  I'm relatively n...</td>\n",
       "      <td>The Anti-Fatigue This is a fantastic product. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426337</th>\n",
       "      <td>B000U0HJMC</td>\n",
       "      <td>1</td>\n",
       "      <td>A3A7T94SGEKY8A</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1231286400</td>\n",
       "      <td>Always the right formula</td>\n",
       "      <td>I trust this brand--the flavors are blended ju...</td>\n",
       "      <td>Always the right formula I trust this brand--t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426338</th>\n",
       "      <td>B000NCW0BC</td>\n",
       "      <td>2</td>\n",
       "      <td>A3B2BB1JFBNAX5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1344124800</td>\n",
       "      <td>Smoked Black Pepper</td>\n",
       "      <td>This pepper is great! I was buying McCormick, ...</td>\n",
       "      <td>Smoked Black Pepper This pepper is great! I wa...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426339</th>\n",
       "      <td>B001D9JC0G</td>\n",
       "      <td>98</td>\n",
       "      <td>A3KZG8XNX5P4HR</td>\n",
       "      <td>5</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1219104000</td>\n",
       "      <td>Canidae Dog Food made my dogs extremely ill</td>\n",
       "      <td>I have relied on Canidae for my 4 dogs for ove...</td>\n",
       "      <td>Canidae Dog Food made my dogs extremely ill I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ProdID  NumProdReviews          UserId  NumUserReviews  \\\n",
       "426335  B00028LDJ2               5  A28AJSK2CI1XAO               1   \n",
       "426336  B000BZZKVS              59   ACHJKSYDTDKMU               2   \n",
       "426337  B000U0HJMC               1  A3A7T94SGEKY8A               3   \n",
       "426338  B000NCW0BC               2  A3B2BB1JFBNAX5               3   \n",
       "426339  B001D9JC0G              98  A3KZG8XNX5P4HR               5   \n",
       "\n",
       "        HelpfulRatio  FoundHelpful  HelpfulVotes  Score        Time  \\\n",
       "426335      1.000000             1             1      3  1203379200   \n",
       "426336      0.750000             3             4      5  1247702400   \n",
       "426337      1.000000             2             2      5  1231286400   \n",
       "426338      0.000000             0             0      5  1344124800   \n",
       "426339      0.857143             6             7      1  1219104000   \n",
       "\n",
       "                                            Summary  \\\n",
       "426335                                    i like it   \n",
       "426336                             The Anti-Fatigue   \n",
       "426337                     Always the right formula   \n",
       "426338                          Smoked Black Pepper   \n",
       "426339  Canidae Dog Food made my dogs extremely ill   \n",
       "\n",
       "                                                     Text  \\\n",
       "426335  Like a lot of the gums by Lotte, the flavor do...   \n",
       "426336  This is a fantastic product.  I'm relatively n...   \n",
       "426337  I trust this brand--the flavors are blended ju...   \n",
       "426338  This pepper is great! I was buying McCormick, ...   \n",
       "426339  I have relied on Canidae for my 4 dogs for ove...   \n",
       "\n",
       "                                                   SumTxt  score2  \n",
       "426335  i like it Like a lot of the gums by Lotte, the...       0  \n",
       "426336  The Anti-Fatigue This is a fantastic product. ...       5  \n",
       "426337  Always the right formula I trust this brand--t...       5  \n",
       "426338  Smoked Black Pepper This pepper is great! I wa...       5  \n",
       "426339  Canidae Dog Food made my dogs extremely ill I ...       0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2, test_set2 = train_test_split(train, test_size = 0.2, random_state = 42, stratify = train['score2'])\n",
    "train_text2, train_score2 = train_set2['SumTxt'], train_set2['score2']\n",
    "test_text2, test_score2 = test_set2['SumTxt'], test_set2['score2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s3 = GridSearchCV(s2, param_grid_s2, n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...\n",
       "                                        LinearSVC(C=10, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='hinge', max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=6,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s3.fit(train_text2, train_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_s3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743 (+/-0.001) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.744 (+/-0.001) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.639 (+/-0.000) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_s3.cv_results_['mean_test_score']\n",
    "stds = grid_s3.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_s3.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s3 = grid_s3.predict(test_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61     30770\n",
      "           5       0.77      0.86      0.81     54498\n",
      "\n",
      "    accuracy                           0.75     85268\n",
      "   macro avg       0.73      0.70      0.71     85268\n",
      "weighted avg       0.74      0.75      0.74     85268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score2, pred_s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>NumProdReviews</th>\n",
       "      <th>UserId</th>\n",
       "      <th>NumUserReviews</th>\n",
       "      <th>HelpfulRatio</th>\n",
       "      <th>FoundHelpful</th>\n",
       "      <th>HelpfulVotes</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SumTxt</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B0001AVRQK</td>\n",
       "      <td>8</td>\n",
       "      <td>A3G38ANYQ3ZYR3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1276387200</td>\n",
       "      <td>Poor taste</td>\n",
       "      <td>I was really disappointed with the Sorghum we ...</td>\n",
       "      <td>Poor taste I was really disappointed with the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B005GV9RZC</td>\n",
       "      <td>2</td>\n",
       "      <td>A263U9SVO11V75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1349308800</td>\n",
       "      <td>Better than US Instant Coffee</td>\n",
       "      <td>A friend who has gone to Korea gave me a coupl...</td>\n",
       "      <td>Better than US Instant Coffee A friend who has...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B004FEN3GK</td>\n",
       "      <td>210</td>\n",
       "      <td>A10AKE9TAADHVV</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1306454400</td>\n",
       "      <td>Hard not to like!</td>\n",
       "      <td>No need for plastic baggies or sloppy tin foil...</td>\n",
       "      <td>Hard not to like! No need for plastic baggies ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B000ED7MR2</td>\n",
       "      <td>7</td>\n",
       "      <td>AT4JRHIZNALRS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1162166400</td>\n",
       "      <td>good company--ok product</td>\n",
       "      <td>I don't care for the flour coating on them and...</td>\n",
       "      <td>good company--ok product I don't care for the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B005K4Q37A</td>\n",
       "      <td>405</td>\n",
       "      <td>A11PM0C1979EZA</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1345766400</td>\n",
       "      <td>Plastic taste</td>\n",
       "      <td>This is the first coffee I tried when I got my...</td>\n",
       "      <td>Plastic taste This is the first coffee I tried...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProdID  NumProdReviews          UserId  NumUserReviews  HelpfulRatio  \\\n",
       "7   B0001AVRQK               8  A3G38ANYQ3ZYR3               1          1.00   \n",
       "8   B005GV9RZC               2  A263U9SVO11V75               1          0.00   \n",
       "9   B004FEN3GK             210  A10AKE9TAADHVV               1          0.00   \n",
       "12  B000ED7MR2               7   AT4JRHIZNALRS               1          0.75   \n",
       "18  B005K4Q37A             405  A11PM0C1979EZA               3          0.75   \n",
       "\n",
       "    FoundHelpful  HelpfulVotes  Score        Time  \\\n",
       "7              3             3      2  1276387200   \n",
       "8              0             0      3  1349308800   \n",
       "9              0             0      4  1306454400   \n",
       "12             3             4      2  1162166400   \n",
       "18             3             4      1  1345766400   \n",
       "\n",
       "                          Summary  \\\n",
       "7                      Poor taste   \n",
       "8   Better than US Instant Coffee   \n",
       "9               Hard not to like!   \n",
       "12       good company--ok product   \n",
       "18                  Plastic taste   \n",
       "\n",
       "                                                 Text  \\\n",
       "7   I was really disappointed with the Sorghum we ...   \n",
       "8   A friend who has gone to Korea gave me a coupl...   \n",
       "9   No need for plastic baggies or sloppy tin foil...   \n",
       "12  I don't care for the flour coating on them and...   \n",
       "18  This is the first coffee I tried when I got my...   \n",
       "\n",
       "                                               SumTxt  score2  \n",
       "7   Poor taste I was really disappointed with the ...       0  \n",
       "8   Better than US Instant Coffee A friend who has...       0  \n",
       "9   Hard not to like! No need for plastic baggies ...       0  \n",
       "12  good company--ok product I don't care for the ...       0  \n",
       "18  Plastic taste This is the first coffee I tried...       0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = train.loc[train['Score'] != 5]\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set3, test_set3 = train_test_split(train2, test_size = 0.2, random_state = 42, stratify = train2['Score'])\n",
    "train_text3, train_score3 = train_set3['SumTxt'], train_set3['Score']\n",
    "test_text3, test_score3 = test_set3['SumTxt'], test_set3['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s4 = GridSearchCV(s2, param_grid_s2, n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...\n",
       "                                        LinearSVC(C=10, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='hinge', max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=6,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_s4.fit(train_text3, train_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_s4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504 (+/-0.003) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.505 (+/-0.005) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.233 (+/-0.041) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_s4.cv_results_['mean_test_score']\n",
    "stds = grid_s4.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_s4.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_s4 = grid_s4.predict(test_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.66      0.56      7839\n",
      "           2       0.19      0.02      0.03      4470\n",
      "           3       0.37      0.09      0.14      6399\n",
      "           4       0.54      0.82      0.65     12062\n",
      "\n",
      "    accuracy                           0.51     30770\n",
      "   macro avg       0.40      0.40      0.35     30770\n",
      "weighted avg       0.44      0.51      0.43     30770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score3, pred_s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='unicode', analyzer='word', min_df=0.1, max_df=0.8)),\n",
    "    ('mnb', MultinomialNB(alpha = 0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_m2 = GridSearchCV(m2, param_grid_s2, n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...code',\n",
       "                                                        sublinear_tf=False,\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('mnb',\n",
       "                                        MultinomialNB(alpha=0.01,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=6,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_m2.fit(train_text3, train_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_m2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454 (+/-0.002) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.455 (+/-0.002) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.399 (+/-0.003) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_m2.cv_results_['mean_test_score']\n",
    "stds = grid_m2.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_m2.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m2 = grid_m2.predict(test_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.31      0.41      7839\n",
      "           2       0.00      0.00      0.00      4470\n",
      "           3       0.40      0.00      0.00      6399\n",
      "           4       0.44      0.96      0.60     12062\n",
      "\n",
      "    accuracy                           0.46     30770\n",
      "   macro avg       0.36      0.32      0.25     30770\n",
      "weighted avg       0.41      0.46      0.34     30770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score3, pred_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_m3 = GridSearchCV(m2, param_grid_s2, n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...code',\n",
       "                                                        sublinear_tf=False,\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('mnb',\n",
       "                                        MultinomialNB(alpha=0.01,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_m3.fit(train_text2, train_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_m3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659 (+/-0.001) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.664 (+/-0.001) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.639 (+/-0.000) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_m3.cv_results_['mean_test_score']\n",
    "stds = grid_m3.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_m3.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_m3 = grid_m3.predict(test_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.08      0.15     30770\n",
      "           5       0.66      0.99      0.79     54498\n",
      "\n",
      "    accuracy                           0.66     85268\n",
      "   macro avg       0.76      0.54      0.47     85268\n",
      "weighted avg       0.73      0.66      0.56     85268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score2, pred_m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(strip_accents='unicode', analyzer='word', min_df=0.1, max_df=0.8)),\n",
    "    ('log', LogisticRegression(C = 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_l2 = GridSearchCV(l2, param_grid_s2, n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_l2.fit(train_text2, train_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_l2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744 (+/-0.002) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.745 (+/-0.002) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.643 (+/-0.001) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_l2.cv_results_['mean_test_score']\n",
    "stds = grid_l2.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_l2.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_l2 = grid_l2.predict(test_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61     30770\n",
      "           5       0.77      0.86      0.81     54498\n",
      "\n",
      "    accuracy                           0.75     85268\n",
      "   macro avg       0.73      0.71      0.71     85268\n",
      "weighted avg       0.74      0.75      0.74     85268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score2, pred_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_l3 = GridSearchCV(l2, param_grid_s2, n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_l3.fit(train_text3, train_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_l3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.516 (+/-0.004) for {'tfidf__ngram_range': (1, 1)}\n",
      "0.515 (+/-0.004) for {'tfidf__ngram_range': (1, 2)}\n",
      "0.401 (+/-0.002) for {'tfidf__ngram_range': (2, 2)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_l3.cv_results_['mean_test_score']\n",
    "stds = grid_l3.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_l3.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_l3 = grid_l3.predict(test_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.63      0.57      7839\n",
      "           2       0.35      0.05      0.09      4470\n",
      "           3       0.40      0.21      0.28      6399\n",
      "           4       0.55      0.78      0.64     12062\n",
      "\n",
      "    accuracy                           0.52     30770\n",
      "   macro avg       0.45      0.42      0.39     30770\n",
      "weighted avg       0.48      0.52      0.47     30770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score3, pred_l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_3 = {#'tfidf__analyzer': [css, csl],\n",
    "#               'tfidf__max_df': [0.8, 0.9, 1],\n",
    "#               'tfidf__min_df': [0.1, 0.2],\n",
    "#               'tfidf__max_features': [50000, None],\n",
    "#               'tfidf__binary': [True, False],\n",
    "#               'tfidf__norm': ['l1', 'l2', None],\n",
    "#               'tfidf__use_idf': [True, False],\n",
    "#               'svm__C': [1, 10, 100],\n",
    "#               'svm__loss': ['hinge']\n",
    "                'tfidf__ngram_range': [(1,3), (1,2), (3,3)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_l4 = GridSearchCV(l2, param_grid_3, n_jobs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.8,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        stri...\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=7,\n",
       "             param_grid={'tfidf__ngram_range': [(1, 3), (1, 2), (3, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_l4.fit(train_text3, train_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidf__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print(grid_l4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515 (+/-0.004) for {'tfidf__ngram_range': (1, 3)}\n",
      "0.515 (+/-0.004) for {'tfidf__ngram_range': (1, 2)}\n",
      "nan (+/-nan) for {'tfidf__ngram_range': (3, 3)}\n"
     ]
    }
   ],
   "source": [
    "means = grid_l4.cv_results_['mean_test_score']\n",
    "stds = grid_l4.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_l4.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_l4 = grid_l4.predict(test_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.63      0.57      7839\n",
      "           2       0.34      0.05      0.09      4470\n",
      "           3       0.39      0.21      0.27      6399\n",
      "           4       0.55      0.78      0.65     12062\n",
      "\n",
      "    accuracy                           0.52     30770\n",
      "   macro avg       0.45      0.42      0.39     30770\n",
      "weighted avg       0.48      0.52      0.47     30770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_score3, pred_l4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
