{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/home/swagmaster/anaconda3/envs/atab/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "import sklearn\n",
    "import mglearn as mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2electricboogaloo.csv')\n",
    "\n",
    "train.Summary.fillna('', inplace=True)\n",
    "train.Text.fillna('', inplace=True)\n",
    "train.SumTxt.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_train = train.loc[train['Score'] == 1]\n",
    "high_train = train.loc[train['Score'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    nopunc = mess.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    nopunc2 = [word for word in nopunc.split() if word.lower() not in stop_words]\n",
    "    return [wnl.lemmatize(word) for word in nopunc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.15, analyzer=text_process)\n",
    "X = vect.fit_transform(low_train['SumTxt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0, n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "coffee        Amazon        cat           eat           chip          \n",
      "cup           box           food          tried         can           \n",
      "tried         order         eating        bad           food          \n",
      "pod           item          eat           really        bag           \n",
      "bean          ordered       day           try           jerky         \n",
      "machine       received      thing         dont          popcorn       \n",
      "Coffee        bag           Diet          smell         salt          \n",
      "Keurig        time          three         food          brand         \n",
      "ground        package       got           tasted        cracker       \n",
      "weak          date          ingredient    stuff         beef          \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "China         dog           tea           ingredient    price         \n",
      "made          food          water         organic       pack          \n",
      "oil           treat         drink         free          oz            \n",
      "seed          formula       chocolate     list          2             \n",
      "Amazon        day           sugar         corn          1             \n",
      "treat         year          coconut       sugar         store         \n",
      "USA           time          bottle        fat           12            \n",
      "say           problem       dont          label         per           \n",
      "plant         sick          sweet         food          size          \n",
      "trap          pet           artificial    contains      box           \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.10, analyzer=text_process)\n",
    "X = vect.fit_transform(low_train['SumTxt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 57534)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "order         bar           price         cat           dog           \n",
      "ordered       salt          store         eating        cat           \n",
      "item          soup          oz            day           treat         \n",
      "received      peanut        cost          thing         eat           \n",
      "package       butter        pack          Diet          China         \n",
      "disappointed  cheese        per           Science       chicken       \n",
      "date          fat           local         got           jerky         \n",
      "return        noodle        1             little        meat          \n",
      "opened        eat           2             always        chew          \n",
      "got           sauce         le            three         pet           \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "cup           new           ingredient    tea           dog           \n",
      "water         formula       sugar         green         day           \n",
      "tasted        year          oil           Tea           problem       \n",
      "try           changed       chip          leaf          popcorn       \n",
      "drink         baby          cooky         drink         week          \n",
      "chocolate     old           list          smell         sick          \n",
      "ever          company       corn          chip          year          \n",
      "smell         recipe        label         licorice      started       \n",
      "Ive           milk          natural       ginger        water         \n",
      "stuff         used          free          chai          use           \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    nopunc = mess.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    nopunc2 = [word for word in nopunc.split() if word.lower() not in stop_words]\n",
    "    nopunc2 = [word.lower() for word in nopunc2]\n",
    "    return [wnl.lemmatize(word) for word in nopunc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.10, analyzer=text_process)\n",
    "X = vect.fit_transform(low_train['SumTxt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "price         order         cat           smell         tea           \n",
      "store         item          eat           water         cup           \n",
      "pack          ordered       ingredient    stuff         chocolate     \n",
      "water         received      chicken       ever          drink         \n",
      "oz            package       meat          ive           green         \n",
      "cost          date          corn          jerky         bitter        \n",
      "bean          return        rice          sauce         kcups         \n",
      "1             disappointed  baby          away          hot           \n",
      "per           arrived       meal          tasted        brand         \n",
      "2             stale         dog           bottle        weak          \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "eat           ingredient    chip          cat           dog           \n",
      "bar           sugar         new           day           treat         \n",
      "cooky         oil           cheese        eating        china         \n",
      "soup          natural       brand         diet          day           \n",
      "butter        organic       changed       science       pet           \n",
      "peanut        artificial    potato        thing         formula       \n",
      "popcorn       syrup         recipe        got           sick          \n",
      "cereal        contains      used          always        vet           \n",
      "free          label         kettle        little        bone          \n",
      "texture       fat           sour          three         year          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    nopunc = mess.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    nopunc2 = [word for word in nopunc.split() if word.lower() not in stop_words]\n",
    "    nopunc2 = [word.lower() for word in nopunc2]\n",
    "    return [stemmer.stem(word) for word in nopunc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.10, analyzer=text_process)\n",
    "X = vect.fit_transform(low_train['SumTxt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "dog           day           chocol        dog           price         \n",
      "china         thing         cup           cat           store         \n",
      "treat         got           kcup          treat         cost          \n",
      "pet           cat           cooki         chicken       oz            \n",
      "caus          littl         roast         formula       per           \n",
      "bone          three         pod           well          pay           \n",
      "chicken       whatev        bean          feed          meat          \n",
      "compani       feed          hot           old           pack          \n",
      "warn          alway         dark          chang         local         \n",
      "problem       real          brew          diet          expens        \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "tea           open          receiv        ingredi       water         \n",
      "mix           can           item          sugar         drink         \n",
      "green         candi         return        contain       bottl         \n",
      "soup          piec          ship          organ         stuff         \n",
      "ever          jerki         date          list          smell         \n",
      "drink         hard          bar           free          coconut       \n",
      "smell         plastic       stale         natur         chip          \n",
      "spice         broken        expir         oil           horribl       \n",
      "brand         jar           pack          label         aw            \n",
      "worst         arriv         compani       corn          salt          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
